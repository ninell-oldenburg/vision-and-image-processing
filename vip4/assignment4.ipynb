{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db10ad2c",
   "metadata": {},
   "source": [
    "   ### Introduction\n",
    "    The goal of the assignment is to implement a prototypical CBIR system. We recommend the use of the CalTech 101 image database http://www.vision.caltech.edu/Image_Datasets/Caltech101/. We recommend that you (for a start) select a subset of say 4-5 categories. When you have checked that everything works you may extend to say 20 categories. For each category, the set of images should be split in two: A training set and a test set (of equal size). The test set must not include images in the training set. When using few categories you may also limit the number of training images (to say 10) per category. Depending on your amount of computational power, for more categories, you may increase the number of training images to the double or more. You should extract visual words using SIFT descriptors (ignoring position, orientation and scale) or similar descriptors extracted at interest points. To compute the descriptors, we recommend to use OpenCV's sift, but other options are possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e564df1b",
   "metadata": {},
   "source": [
    "### Codebook Generation\n",
    "    In order to generate a code book, select a set of training images. Then Extract SIFT features from the training images (ignore position, orientation and scale). The SIFT features should be concatenated into a matrix, one descriptor per row. Then you should run the k-means clustering algorithm on the subset of training descriptors to extract good prototype (visual word) clusters. A reasonable k should be small (say between 200 and 500) for a small number of categories (say 5) and larger (say between 500 and 2000) for a larger number of categories. Also, a good value of k may depend on the complexity of your data. You should experiment with a few di erent values of k (but beware that this can be rather time-consuming). Once clustering has been obtained, classify each training descriptor to the closest cluster centers) and form the bag of words (BoW) for each image in the image training set. Note that there may exist several implementations of k-means available in several libraries, e.g. in OpenCV and in scikit-image. These implementations may dffer both with respect to function, parameters and processing time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7deacd",
   "metadata": {},
   "source": [
    "  ### Indexing\n",
    "    The next step consists in content indexing. For each image in the test set you\n",
    "    should:\n",
    "       \n",
    "    a) Extract the SIFT descriptors of the feature points in the image\n",
    "    b) Project the descriptors onto the codebook, i.e., for each descriptor the closest cluster prototype should be found\n",
    "    c) Construct the generated corresponding bag of words, i.e, word histogram.\n",
    "\n",
    "    Please note that you have already performed the same steps for the training images during codebook generation. Now construct and save a table that would contain, per entry at least the file name, the true category, if it belongs to the training- or test set, and the corresponding bag of words / word histogram. The table need only be computed once and then used repeatably in the following retrieval experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7799404e",
   "metadata": {},
   "source": [
    "### Retrieving\n",
    "    Finally, you should implement retrieving of images using some of the similarity\n",
    "    measures discussed in the course slides. You may use:\n",
    "    \n",
    "    a) common words\n",
    "    b) tf-ifd similarity\n",
    "    c) Bhattacharyya distance or Kullback-Leibler divergence\n",
    "      \n",
    "    Please argue for your choice or report the differences in result when applying the different measures. Your report should show commented results for two experiments. In the first you consider retrieving training images. In the second you test how well you can classify test images. Otherwise the two test are identical. For each test you should count:\n",
    "    \n",
    "    a) The mean reciprocal rank (i.e. the average across all queries of 1=ranki, where ranki is the rank position of the first correct category for the i'th query).\n",
    "    b) How often (in per cent) the correct category is in top-3\n",
    "\n",
    "    Please note that the measures above are just two among a long list of possible performance measures. If you google Information retrieval you may  find alternative measures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5cc16d",
   "metadata": {},
   "source": [
    "    The report should be kept within 8 pages including everything. About half may show results in form of tables, graphs, and images. Remember to write what the tables and graphs should show. Important decisions, choices, and results should be discussed and explained. In particular, strage/false results should be identified and possible causes should be explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "1b63de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important packages\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage.io import imread\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "bd94da6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-237-2d898c49b6a6>:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tmp_images = np.array([imread(os.path.join(tmp_path, fname)) for fname in os.listdir(tmp_path) if fname.endswith('.jpg')])\n",
      "<ipython-input-237-2d898c49b6a6>:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  final_array = np.array(all_images)\n"
     ]
    }
   ],
   "source": [
    "# Loading 5 categories from the CALTECH101 corpus\n",
    "def load_images(main_folder, n_categories):\n",
    "    '''\n",
    "    Loads images from multiple categories into one array.\n",
    "    \n",
    "    Arguments\n",
    "    main_folder: folder where subfolders with categories exist\n",
    "    n_categories: number of categories loaded\n",
    "    \n",
    "    Returns\n",
    "    final_array: array with dimension (n_categories,) consisting of subarrays with images from each category\n",
    "    cat: order of categories\n",
    "    '''\n",
    "    dr = os.listdir(main_folder)\n",
    "    cat = dr[0:n_categories]\n",
    "    all_images = []\n",
    "    all_filenames = []\n",
    "\n",
    "    for idx_cat, i in enumerate(cat):    \n",
    "        tmp_path = os.path.join(\"101_ObjectCategories\", i)\n",
    "        tmp_images = np.array([imread(os.path.join(tmp_path, fname)) for fname in os.listdir(tmp_path) if fname.endswith('.jpg')])\n",
    "        all_images.append(tmp_images)\n",
    "        all_filenames.append(os.listdir(tmp_path))\n",
    "        \n",
    "    final_array = np.array(all_images)\n",
    "    return final_array, cat, all_filenames\n",
    "        \n",
    "all_images, order, all_filenames = load_images(\"101_ObjectCategories\", 5)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "911b8201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['image_0032.jpg',\n",
       "  'image_0026.jpg',\n",
       "  'image_0027.jpg',\n",
       "  'image_0033.jpg',\n",
       "  'image_0019.jpg',\n",
       "  'image_0025.jpg',\n",
       "  'image_0031.jpg',\n",
       "  'image_0030.jpg',\n",
       "  'image_0024.jpg',\n",
       "  'image_0018.jpg',\n",
       "  'image_0020.jpg',\n",
       "  'image_0034.jpg',\n",
       "  'image_0008.jpg',\n",
       "  'image_0009.jpg',\n",
       "  'image_0021.jpg',\n",
       "  'image_0023.jpg',\n",
       "  'image_0022.jpg',\n",
       "  'image_0013.jpg',\n",
       "  'image_0007.jpg',\n",
       "  'image_0006.jpg',\n",
       "  'image_0012.jpg',\n",
       "  'image_0004.jpg',\n",
       "  'image_0010.jpg',\n",
       "  'image_0011.jpg',\n",
       "  'image_0005.jpg',\n",
       "  'image_0001.jpg',\n",
       "  'image_0015.jpg',\n",
       "  'image_0029.jpg',\n",
       "  'image_0028.jpg',\n",
       "  'image_0014.jpg',\n",
       "  'image_0016.jpg',\n",
       "  'image_0002.jpg',\n",
       "  'image_0003.jpg',\n",
       "  'image_0017.jpg'],\n",
       " ['image_0032.jpg',\n",
       "  'image_0026.jpg',\n",
       "  'image_0027.jpg',\n",
       "  'image_0033.jpg',\n",
       "  'image_0019.jpg',\n",
       "  'image_0025.jpg',\n",
       "  'image_0031.jpg',\n",
       "  'image_0030.jpg',\n",
       "  'image_0024.jpg',\n",
       "  'image_0018.jpg',\n",
       "  'image_0020.jpg',\n",
       "  'image_0034.jpg',\n",
       "  'image_0008.jpg',\n",
       "  'image_0009.jpg',\n",
       "  'image_0035.jpg',\n",
       "  'image_0021.jpg',\n",
       "  'image_0037.jpg',\n",
       "  'image_0023.jpg',\n",
       "  'image_0022.jpg',\n",
       "  'image_0036.jpg',\n",
       "  'image_0079.jpg',\n",
       "  'image_0051.jpg',\n",
       "  'image_0045.jpg',\n",
       "  'image_0092.jpg',\n",
       "  'image_0086.jpg',\n",
       "  'image_0087.jpg',\n",
       "  'image_0093.jpg',\n",
       "  'image_0044.jpg',\n",
       "  'image_0050.jpg',\n",
       "  'image_0078.jpg',\n",
       "  'image_0046.jpg',\n",
       "  'image_0052.jpg',\n",
       "  'image_0085.jpg',\n",
       "  'image_0091.jpg',\n",
       "  'image_0090.jpg',\n",
       "  'image_0084.jpg',\n",
       "  'image_0053.jpg',\n",
       "  'image_0047.jpg',\n",
       "  'image_0043.jpg',\n",
       "  'image_0057.jpg',\n",
       "  'image_0080.jpg',\n",
       "  'image_0094.jpg',\n",
       "  'image_0095.jpg',\n",
       "  'image_0081.jpg',\n",
       "  'image_0056.jpg',\n",
       "  'image_0042.jpg',\n",
       "  'image_0054.jpg',\n",
       "  'image_0040.jpg',\n",
       "  'image_0068.jpg',\n",
       "  'image_0097.jpg',\n",
       "  'image_0083.jpg',\n",
       "  'image_0082.jpg',\n",
       "  'image_0096.jpg',\n",
       "  'image_0069.jpg',\n",
       "  'image_0041.jpg',\n",
       "  'image_0055.jpg',\n",
       "  'image_0058.jpg',\n",
       "  'image_0070.jpg',\n",
       "  'image_0064.jpg',\n",
       "  'image_0065.jpg',\n",
       "  'image_0071.jpg',\n",
       "  'image_0059.jpg',\n",
       "  'image_0067.jpg',\n",
       "  'image_0073.jpg',\n",
       "  'image_0098.jpg',\n",
       "  'image_0099.jpg',\n",
       "  'image_0072.jpg',\n",
       "  'image_0066.jpg',\n",
       "  'image_0062.jpg',\n",
       "  'image_0076.jpg',\n",
       "  'image_0089.jpg',\n",
       "  'image_0088.jpg',\n",
       "  'image_0077.jpg',\n",
       "  'image_0063.jpg',\n",
       "  'image_0075.jpg',\n",
       "  'image_0061.jpg',\n",
       "  'image_0049.jpg',\n",
       "  'image_0048.jpg',\n",
       "  'image_0060.jpg',\n",
       "  'image_0074.jpg',\n",
       "  'image_0100.jpg',\n",
       "  'image_0013.jpg',\n",
       "  'image_0007.jpg',\n",
       "  'image_0006.jpg',\n",
       "  'image_0012.jpg',\n",
       "  'image_0038.jpg',\n",
       "  'image_0004.jpg',\n",
       "  'image_0010.jpg',\n",
       "  'image_0011.jpg',\n",
       "  'image_0005.jpg',\n",
       "  'image_0039.jpg',\n",
       "  'image_0001.jpg',\n",
       "  'image_0015.jpg',\n",
       "  'image_0029.jpg',\n",
       "  'image_0028.jpg',\n",
       "  'image_0014.jpg',\n",
       "  'image_0016.jpg',\n",
       "  'image_0002.jpg',\n",
       "  'image_0003.jpg',\n",
       "  'image_0017.jpg'],\n",
       " ['image_0032.jpg',\n",
       "  'image_0026.jpg',\n",
       "  'image_0027.jpg',\n",
       "  'image_0033.jpg',\n",
       "  'image_0019.jpg',\n",
       "  'image_0025.jpg',\n",
       "  'image_0031.jpg',\n",
       "  'image_0030.jpg',\n",
       "  'image_0024.jpg',\n",
       "  'image_0018.jpg',\n",
       "  'image_0020.jpg',\n",
       "  'image_0034.jpg',\n",
       "  'image_0008.jpg',\n",
       "  'image_0009.jpg',\n",
       "  'image_0035.jpg',\n",
       "  'image_0021.jpg',\n",
       "  'image_0037.jpg',\n",
       "  'image_0023.jpg',\n",
       "  'image_0022.jpg',\n",
       "  'image_0036.jpg',\n",
       "  'image_0042.jpg',\n",
       "  'image_0040.jpg',\n",
       "  'image_0041.jpg',\n",
       "  'image_0013.jpg',\n",
       "  'image_0007.jpg',\n",
       "  'image_0006.jpg',\n",
       "  'image_0012.jpg',\n",
       "  'image_0038.jpg',\n",
       "  'image_0004.jpg',\n",
       "  'image_0010.jpg',\n",
       "  'image_0011.jpg',\n",
       "  'image_0005.jpg',\n",
       "  'image_0039.jpg',\n",
       "  'image_0001.jpg',\n",
       "  'image_0015.jpg',\n",
       "  'image_0029.jpg',\n",
       "  'image_0028.jpg',\n",
       "  'image_0014.jpg',\n",
       "  'image_0016.jpg',\n",
       "  'image_0002.jpg',\n",
       "  'image_0003.jpg',\n",
       "  'image_0017.jpg'],\n",
       " ['image_0032.jpg',\n",
       "  'image_0026.jpg',\n",
       "  'image_0027.jpg',\n",
       "  'image_0033.jpg',\n",
       "  'image_0019.jpg',\n",
       "  'image_0025.jpg',\n",
       "  'image_0031.jpg',\n",
       "  'image_0030.jpg',\n",
       "  'image_0024.jpg',\n",
       "  'image_0018.jpg',\n",
       "  'image_0020.jpg',\n",
       "  'image_0034.jpg',\n",
       "  'image_0008.jpg',\n",
       "  'image_0009.jpg',\n",
       "  'image_0035.jpg',\n",
       "  'image_0021.jpg',\n",
       "  'image_0037.jpg',\n",
       "  'image_0023.jpg',\n",
       "  'image_0022.jpg',\n",
       "  'image_0036.jpg',\n",
       "  'image_0042.jpg',\n",
       "  'image_0040.jpg',\n",
       "  'image_0041.jpg',\n",
       "  'image_0013.jpg',\n",
       "  'image_0007.jpg',\n",
       "  'image_0006.jpg',\n",
       "  'image_0012.jpg',\n",
       "  'image_0038.jpg',\n",
       "  'image_0004.jpg',\n",
       "  'image_0010.jpg',\n",
       "  'image_0011.jpg',\n",
       "  'image_0005.jpg',\n",
       "  'image_0039.jpg',\n",
       "  'image_0001.jpg',\n",
       "  'image_0015.jpg',\n",
       "  'image_0029.jpg',\n",
       "  'image_0028.jpg',\n",
       "  'image_0014.jpg',\n",
       "  'image_0016.jpg',\n",
       "  'image_0002.jpg',\n",
       "  'image_0003.jpg',\n",
       "  'image_0017.jpg'],\n",
       " ['image_0032.jpg',\n",
       "  'image_0026.jpg',\n",
       "  'image_0027.jpg',\n",
       "  'image_0033.jpg',\n",
       "  'image_0019.jpg',\n",
       "  'image_0025.jpg',\n",
       "  'image_0031.jpg',\n",
       "  'image_0030.jpg',\n",
       "  'image_0024.jpg',\n",
       "  'image_0018.jpg',\n",
       "  'image_0020.jpg',\n",
       "  'image_0034.jpg',\n",
       "  'image_0008.jpg',\n",
       "  'image_0009.jpg',\n",
       "  'image_0035.jpg',\n",
       "  'image_0021.jpg',\n",
       "  'image_0037.jpg',\n",
       "  'image_0023.jpg',\n",
       "  'image_0022.jpg',\n",
       "  'image_0036.jpg',\n",
       "  'image_0079.jpg',\n",
       "  'image_0051.jpg',\n",
       "  'image_0045.jpg',\n",
       "  'image_0086.jpg',\n",
       "  'image_0087.jpg',\n",
       "  'image_0044.jpg',\n",
       "  'image_0050.jpg',\n",
       "  'image_0078.jpg',\n",
       "  'image_0046.jpg',\n",
       "  'image_0052.jpg',\n",
       "  'image_0085.jpg',\n",
       "  'image_0091.jpg',\n",
       "  'image_0090.jpg',\n",
       "  'image_0084.jpg',\n",
       "  'image_0053.jpg',\n",
       "  'image_0047.jpg',\n",
       "  'image_0043.jpg',\n",
       "  'image_0057.jpg',\n",
       "  'image_0080.jpg',\n",
       "  'image_0081.jpg',\n",
       "  'image_0056.jpg',\n",
       "  'image_0042.jpg',\n",
       "  'image_0054.jpg',\n",
       "  'image_0040.jpg',\n",
       "  'image_0068.jpg',\n",
       "  'image_0083.jpg',\n",
       "  'image_0082.jpg',\n",
       "  'image_0069.jpg',\n",
       "  'image_0041.jpg',\n",
       "  'image_0055.jpg',\n",
       "  'image_0058.jpg',\n",
       "  'image_0070.jpg',\n",
       "  'image_0064.jpg',\n",
       "  'image_0065.jpg',\n",
       "  'image_0071.jpg',\n",
       "  'image_0059.jpg',\n",
       "  'image_0067.jpg',\n",
       "  'image_0073.jpg',\n",
       "  'image_0072.jpg',\n",
       "  'image_0066.jpg',\n",
       "  'image_0062.jpg',\n",
       "  'image_0076.jpg',\n",
       "  'image_0089.jpg',\n",
       "  'image_0088.jpg',\n",
       "  'image_0077.jpg',\n",
       "  'image_0063.jpg',\n",
       "  'image_0075.jpg',\n",
       "  'image_0061.jpg',\n",
       "  'image_0049.jpg',\n",
       "  'image_0048.jpg',\n",
       "  'image_0060.jpg',\n",
       "  'image_0074.jpg',\n",
       "  'image_0013.jpg',\n",
       "  'image_0007.jpg',\n",
       "  'image_0006.jpg',\n",
       "  'image_0012.jpg',\n",
       "  'image_0038.jpg',\n",
       "  'image_0004.jpg',\n",
       "  'image_0010.jpg',\n",
       "  'image_0011.jpg',\n",
       "  'image_0005.jpg',\n",
       "  'image_0039.jpg',\n",
       "  'image_0001.jpg',\n",
       "  'image_0015.jpg',\n",
       "  'image_0029.jpg',\n",
       "  'image_0028.jpg',\n",
       "  'image_0014.jpg',\n",
       "  'image_0016.jpg',\n",
       "  'image_0002.jpg',\n",
       "  'image_0003.jpg',\n",
       "  'image_0017.jpg']]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "cf2e2830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing dataset and dividing into test and train \n",
    "\n",
    "def train_test_split(image_set, trainsize = 10, testsize = 5):\n",
    "\n",
    "    # gerenuk = all_images[0]\n",
    "\n",
    "    all_elements = np.random.choice(len(image_set), trainsize+testsize)\n",
    "\n",
    "    train_elements = all_elements[1:trainsize+1]\n",
    "    test_elements = all_elements[-testsize:]\n",
    "\n",
    "    train_images = image_set[train_elements]\n",
    "    \n",
    "    test_images = image_set[test_elements]\n",
    "    \n",
    "    return train_images, test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "1ee6eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gerenuk = all_images[0]\n",
    "\n",
    "# Train test split\n",
    "train = []\n",
    "train_files = []\n",
    "test = []\n",
    "test_files = []\n",
    "\n",
    "# Applying test_train split to every category\n",
    "for image_set in all_images:\n",
    "    train_images, test_images = train_test_split(image_set)\n",
    "    train.append(train_images)\n",
    "    test.append(test_images)\n",
    "    \n",
    "train = np.array(train)\n",
    "\n",
    "test = np.array(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "d6f9302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from https://docs.opencv.org/3.4/da/df5/tutorial_py_sift_intro.html\n",
    "\n",
    "test_img = train[0][0]\n",
    "\n",
    "# Grayscale image\n",
    "gray = cv2.cvtColor(test_img.copy(), cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Sift engine\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Key points\n",
    "kp = sift.detect(gray, None)\n",
    "\n",
    "# Image with keypoints\n",
    "img = cv2.drawKeypoints(gray, kp, test_img.copy(), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "kp, des = sift.compute(gray,kp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8bc5dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift_descriptors(img):\n",
    "    if len(img.shape) > 2:\n",
    "            # Grayscale image\n",
    "        gray = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = img.copy()\n",
    "        # Sift engine\n",
    "    sift = cv2.SIFT_create()\n",
    "    # Key points\n",
    "    kp = sift.detect(gray, None)\n",
    "    # Image with keypoints\n",
    "    # img = cv2.drawKeypoints(gray, kp, test_img.copy(), flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    _ , des = sift.compute(gray, kp)\n",
    "\n",
    "    return des\n",
    "\n",
    "\n",
    "# The SIFT features should be concatenated into a matrix, one descriptor per row.\n",
    "for set_idx, train_sets in enumerate(train):    \n",
    "    for img in train_sets:\n",
    "        des = sift_descriptors(img)        \n",
    "        if set_idx == 0:\n",
    "            descriptors = des\n",
    "        else:\n",
    "            #np.append(descriptors, des, axis=0)\n",
    "            np.concatenate((descriptors, des), axis=0)\n",
    "            #np.vstack((descriptors, des))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "2e510e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then you should run the k-means clustering algorithm on the subset of training descriptors to extract good prototype (visual word) clusters. \n",
    "# A reasonable k should be small (say b$etween 200 and 500) for a small number of categories (say 5) \n",
    "# and larger (say between 500 and 2000) for a larger number of categories. \n",
    "# Also, a good value of k may depend on the complexity of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "805d98a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspiration from https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "# Maybe use this link to demonstrate why scipy is nice https://hdbscan.readthedocs.io/en/latest/performance_and_scalability.html#comparison-of-high-performance-implementations\n",
    "from scipy.cluster.vq import vq, kmeans, whiten\n",
    "\n",
    "# Normalize (by standard deviation)\n",
    "whitened = whiten(descriptors)\n",
    "codebook, distortion = kmeans(whitened, 200)\n",
    "\n",
    "\n",
    "# Assigns a code from a code book to each observation. \n",
    "# Each observation vector in the ‘M’ by ‘N’ obs array is compared with the centroids in the code book and assigned the code of the closest centroid.\n",
    "# The code book is usually generated using the k-means algorithm. \n",
    "# Each row of the array holds a different code, and the columns are the features of the code.\n",
    "# assigned_features = vq(whitened, codebook)\n",
    "\n",
    "# whitened[:, 0], whitened[:, 1]\n",
    "# is\n",
    "# codebook[:, 0], codebook[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "0333ee38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(730, 128)\n",
      "(730, 128)\n"
     ]
    }
   ],
   "source": [
    "print(whitened.shape)\n",
    "print(descriptors.shape)\n",
    "# Nice description: https://www.unioviedo.es/compnum/labs/new/kmeans.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "74a7f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vq returns:\n",
    "# code - A length M array holding the code book index for each observation.\n",
    "# dist - The distortion (distance) between the observation and its nearest code.\n",
    "code_idx, dist = vq(whitened, codebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "3493d420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.8663638 , 0.771305  , 0.69173235, 0.54447997, 0.15860964,\n",
       "       0.04201819, 0.16977328, 0.32766712, 0.77998805, 1.7848425 ,\n",
       "       1.7181492 , 0.35854688, 0.04632722, 0.03957662, 0.01229949,\n",
       "       0.20783515, 0.11275943, 1.0003595 , 4.1879134 , 3.1920516 ,\n",
       "       0.19057961, 0.04719809, 0.03523283, 0.08143103, 0.02259532,\n",
       "       0.2909345 , 3.0537775 , 3.6235478 , 0.19690686, 0.03522928,\n",
       "       0.10290167, 0.20894162, 0.55486125, 0.1894089 , 0.23230074,\n",
       "       1.0746602 , 0.43595812, 0.1487209 , 0.22226147, 0.219624  ,\n",
       "       2.6009781 , 1.1847336 , 0.47451186, 0.23045476, 0.26166275,\n",
       "       0.43751708, 0.6072514 , 2.1846387 , 0.5165382 , 0.5113899 ,\n",
       "       1.8540624 , 2.3846767 , 3.1372316 , 1.4169523 , 0.6361868 ,\n",
       "       1.0997913 , 1.6547092 , 0.9151357 , 1.0036927 , 1.1578718 ,\n",
       "       0.558645  , 0.28171107, 0.8289141 , 2.1941402 , 0.320693  ,\n",
       "       0.15846561, 0.1516094 , 0.28293324, 0.26785526, 0.6249685 ,\n",
       "       0.6096483 , 0.32959163, 2.1943471 , 1.895902  , 1.3635334 ,\n",
       "       0.94508964, 0.3856604 , 0.16918598, 0.55941653, 1.3412646 ,\n",
       "       0.8049788 , 1.0112232 , 1.4278857 , 3.0621364 , 2.501746  ,\n",
       "       0.5113415 , 0.14008605, 0.27559844, 3.6396065 , 2.8237839 ,\n",
       "       0.24210899, 0.38233593, 0.4635042 , 0.20208563, 0.36463487,\n",
       "       2.2081568 , 0.13475102, 0.2828367 , 0.7045491 , 0.6413651 ,\n",
       "       0.29931197, 1.2247019 , 0.8250882 , 0.5028474 , 0.46803698,\n",
       "       1.0777774 , 1.1657948 , 1.0657033 , 0.79867965, 0.9149628 ,\n",
       "       0.1985929 , 0.11542839, 0.42678604, 0.60952723, 0.87150127,\n",
       "       2.6340728 , 2.258067  , 0.29166165, 0.10562801, 0.19178484,\n",
       "       2.6199305 , 2.892897  , 0.44552556, 0.9154133 , 0.2062027 ,\n",
       "       0.02573966, 0.13518788, 0.64451414], dtype=float32)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(code_idx[0]) # Descriptor number 0 has prototype at codebook index 163 \n",
    "codebook[code_idx[0]] # And that prototype looks like this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6a5a9312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gerenuk\n",
      "hawksbill\n",
      "headphone\n",
      "ant\n",
      "butterfly\n"
     ]
    }
   ],
   "source": [
    "# Indexing\n",
    "# Now construct and save a table that would contain, per entry at least the file name, the true category, if it belongs to the training- or test set, and the corresponding bag of words / word histogram. \n",
    "# The table need only be computed once and then used repeatably in the following retrieval experiments.\n",
    "\n",
    "from collections import Counter\n",
    "bow_train = []\n",
    "\n",
    "# The SIFT features should be concatenated into a matrix, one descriptor per row.\n",
    "for set_idx, train_sets in enumerate(train): \n",
    "    print(order[set_idx])\n",
    "    for img in train_sets:\n",
    "        # Find descriptors\n",
    "        des = sift_descriptors(img)\n",
    "        # Whiten\n",
    "        single_whit = whiten(des)\n",
    "        # Find distribution of codes\n",
    "        single_code_idx, _ = vq(single_whit, codebook)\n",
    "        # Histogram\n",
    "        #c = Counter(single_code_idx)\n",
    "        imhist = np.zeros((codebook.shape[0]))\n",
    "        for idx in single_code_idx:\n",
    "            imhist[idx] += 1\n",
    "        # filename\n",
    "        l = [\"train\", order[set_idx], imhist]\n",
    "    \n",
    "        bow_train.append(l)\n",
    "\n",
    "bow_test = []       \n",
    "for set_idx, test_sets in enumerate(test): \n",
    "    for img in test_sets:\n",
    "        # Find descriptors\n",
    "        des = sift_descriptors(img)\n",
    "        # Whiten\n",
    "        single_whit = whiten(des)\n",
    "        # Find distribution of codes\n",
    "        single_code_idx, _ = vq(single_whit, codebook)\n",
    "        # Histogram\n",
    "        imhist = np.zeros((codebook.shape[0]))\n",
    "        for idx in single_code_idx:\n",
    "            imhist[idx] += 1\n",
    "        #c = Counter(single_code_idx)\n",
    "        \n",
    "        l = [\"test\", order[set_idx], imhist]\n",
    "        \n",
    "        bow_test.append(l)\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a9185aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-251-07f4e3dea0bf>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  bow_train = np.array(bow_train)\n",
      "<ipython-input-251-07f4e3dea0bf>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  bow_test = np.array(bow_test)\n"
     ]
    }
   ],
   "source": [
    "# Now we have a list with histograms of prototypes per train image \n",
    "bow_train = np.array(bow_train)\n",
    "\n",
    "# Now we have a list with histograms of prototypes per test image \n",
    "bow_test = np.array(bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "81f167a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import kl_div \n",
    "score = []\n",
    "kls = []\n",
    "# Distances \n",
    "test_hist = bow_test[0]\n",
    "\n",
    "for hist in bow_test:\n",
    "    # compute the distance between the two histograms\n",
    "    # using the method and update the results dictionary\n",
    "    # kls.append(kl_div(test_hist[2], hist[2]))\n",
    "    # Formula taken from https://github.com/JaggerWu/images-retrieving/blob/master/CodeBook_generation.py\n",
    "    score.append(np.sqrt(sum((test_hist[2]-hist[2])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e7c1877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.array(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a0f9ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_location = np.where(score == min(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "24e049d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[min_location]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
