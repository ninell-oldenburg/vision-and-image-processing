{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee051f50",
   "metadata": {},
   "source": [
    "For both all datasets manipulation and reshaping is very important to maintain good\n",
    "performances. Both Matlab and Python/Numpy allow you to extract a subarray as a list\n",
    "of value, and affects a list of value to an image subarray. Woodham’s estimation can be\n",
    "vectorised. You may want to look at integration source code to see how Python allows for\n",
    "these type of manipulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96029d9a",
   "metadata": {},
   "source": [
    "Each of these functions are reasonably well documented using docstrings, so, after importing\n",
    "ps utils.py, you can invoke help(ps utils) for the entire documentation, or for a specific\n",
    "function such as help(ransac 3dvector) etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537d8098",
   "metadata": {},
   "source": [
    "### Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4208721",
   "metadata": {},
   "source": [
    "    shiny vase Dataset\n",
    "\n",
    "    Buddha is real dataset, with exactly 10 images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6134b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import utils.ps_utils as utils\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa8bb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"Buddha.mat\"\n",
    "\n",
    "path = os.path.join(\"utils\", filename)\n",
    "# Reading shiny vase matlab file\n",
    "# I - 3D array of image size (m,n,k) where k is views\n",
    "# mask - with records of intensity data\n",
    "# S - light vectors \n",
    "I, mask, S = utils.read_data_file(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e10a6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b01c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the 3 available images of beethoven\n",
    "#fig, axes = plt.subplots(1, 10)\n",
    "#ax = axes.ravel()\n",
    "\n",
    "# images = data.stereo_motorcycle()\n",
    "#ax[0].imshow(I[:,:,0],cmap = 'Greys_r');\n",
    "#ax[1].imshow(I[:,:,1],cmap = 'Greys_r');\n",
    "#ax[2].imshow(I[:,:,2],cmap = 'Greys_r');\n",
    "#ax[3].imshow(I[:,:,3],cmap = 'Greys_r');\n",
    "#ax[4].imshow(I[:,:,4],cmap = 'Greys_r');\n",
    "#ax[5].imshow(I[:,:,5],cmap = 'Greys_r');\n",
    "#ax[6].imshow(I[:,:,6],cmap = 'Greys_r');\n",
    "#ax[7].imshow(I[:,:,7],cmap = 'Greys_r');\n",
    "#ax[8].imshow(I[:,:,8],cmap = 'Greys_r');\n",
    "#ax[9].imshow(I[:,:,9],cmap = 'Greys_r');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032ecfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask, cmap = 'Greys_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b66457",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask * I[:,:,0], cmap= 'Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34682ed8",
   "metadata": {},
   "source": [
    "    If nz is the number of pixels inside the non-zero part of the mask, You should create an array J of size/shape (10, nz)  and obtain the albedo modulated normal field as M = S^|J (the pseudo-inverse). With it, extract the albedo within the mask, display it as a 2D image. Then extract the normal field by normalizing M ,extract its components n1, n2, n3. Solve for depth and display it at different view points. Comment on what happens here. Do you think that RANSAC could provide a better estimation of normals? Explain. \n",
    "    \n",
    "    You should try and replace Woodham’s first step (via inverse/pseudoinverse) with RANSAC estimation. The threshold parameter in ransac 3dvector() should no more than be 2.0. After the estimation for each pixel, extract the normals and the albedo. Display and comment on the results. Do they differ from Woodham’s estimation? Try then to make the estimated normal field smoother using the smooth normal field() function. You may experiment with the iters parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7224982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix and vector approach\n",
    "\n",
    "# If nz is the number of pixels inside the non-zero part of the mask, You should create an array J of size/shape (10, nz)\n",
    "J = np.ndarray((I.shape[2], len(mask[mask!=0]))) \n",
    "J.shape\n",
    "\n",
    "# Taking every img angle in I and saving pixels that are non-zero\n",
    "for i in range(0, I.shape[2]):\n",
    "    # Extract only pixels in the mask\n",
    "    # Save as i in J\n",
    "    J[i] = I[:,:,i][mask!=0]\n",
    "    \n",
    "# Extracting m with the pseudo inverse function\n",
    "M = np.linalg.pinv(S)@J\n",
    "albedo = np.linalg.norm(M, axis=0)\n",
    "\n",
    "# Finding albedo within the mask\n",
    "albedo_mask = np.zeros(mask.shape)\n",
    "albedo_mask[mask!=0] = albedo\n",
    "\n",
    "# Calculating normals\n",
    "normal = (1/ np.linalg.norm(M, axis=0))*M\n",
    "\n",
    "# Componenets\n",
    "c1, c2, c3 = normal\n",
    "\n",
    "# Building matrix from mask and normals\n",
    "n1 = np.zeros(mask.shape)\n",
    "n1[mask!=0] = c1\n",
    "\n",
    "n2 = np.zeros(mask.shape)\n",
    "n2[mask!=0] = c2\n",
    "\n",
    "n3 = np.zeros(mask.shape)\n",
    "n3[mask!=0] = c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155c007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel by pixel approach\n",
    "\n",
    "M = []\n",
    "albedo = []\n",
    "normal = []\n",
    "\n",
    "# Per row in image\n",
    "for i in range(0,I.shape[0]):\n",
    "    # idx += 1\n",
    "    # Per column in image\n",
    "    for j in range(0, I.shape[1]):\n",
    "        # If the position in the mask is non-zero\n",
    "        # Apply RANSAC to the image pixel\n",
    "        if mask[i,j]!=0:\n",
    "            j = I[i,j,:]\n",
    "            m = np.linalg.pinv(S)@j\n",
    "            p = np.linalg.norm(m)\n",
    "            n = (1/ np.linalg.norm(m))*m\n",
    "            \n",
    "            albedo.append(p)\n",
    "            M.append(m)\n",
    "            normal.append(n)\n",
    "            \n",
    "normal = np.array(normal).reshape(3, 49872)           \n",
    "M = np.array(M).reshape(3, 49872)\n",
    "albedo = np.array(albedo)\n",
    "\n",
    "c1, c2, c3 = normal\n",
    "\n",
    "n1 = np.zeros(mask.shape)\n",
    "n1[mask!=0] = c1\n",
    "\n",
    "n2 = np.zeros(mask.shape)\n",
    "n2[mask!=0] = c2\n",
    "\n",
    "n3 = np.zeros(mask.shape)\n",
    "n3[mask!=0] = c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a93fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(utils.simchony_integrate)\n",
    "# n1, n2, n3: nympy float arrays the 3 components of the normal. They must be 2D arrays\n",
    "# Copying the mask\n",
    "z = utils.simchony_integrate(n1, n2, n3, mask)\n",
    "z_unbiased = utils.unbiased_integrate(n1, n2, n3, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20ce72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "z[np.isnan(z)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def38eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(utils.display_surface)\n",
    "#utils.display_surface(z, albedo=albedo_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68808acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#![algorithm_ps.png](attachment:algorithm_ps.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed80981",
   "metadata": {},
   "source": [
    "    Do you think that RANSAC could provide a better estimation of normals? Explain. You should try and replace Woodham's first step (via inverse/pseudoinverse) with RANSAC estimation. The threshold parameter in ransac_3dvector() should no more than be 2.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa66bd",
   "metadata": {},
   "source": [
    "    When using RANSAC, however, an estimation of albedo and normal will have to be performed one pixel at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46389f5c",
   "metadata": {},
   "source": [
    "    After the estimation for each pixel, extract the normals and the albedo. Display and comment on the results. Do they differ from Woodham's estimation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a195f968",
   "metadata": {},
   "outputs": [],
   "source": [
    "ransac = []\n",
    "albedo = []\n",
    "normal = []\n",
    "\n",
    "# Per row in image\n",
    "for i in range(0,I.shape[0]):\n",
    "    # Per column in image\n",
    "    for j in range(0, I.shape[1]):\n",
    "        # If the position in the mask is non-zero\n",
    "        # Apply RANSAC to the image pixel\n",
    "        if mask[i,j]!=0:\n",
    "            m, inliers, best_fit = utils.ransac_3dvector(data=(I[i,j,:], S), threshold = 25.0)\n",
    "            p = np.linalg.norm(m, axis=0)\n",
    "            n = (1/ np.linalg.norm(m, axis=0))*m\n",
    "            \n",
    "            albedo.append(p)\n",
    "            ransac.append(m)\n",
    "            normal.append(n)\n",
    "            \n",
    "normal = np.array(normal).reshape(3, 24828)           \n",
    "ransac = np.array(ransac).reshape(3, 24828)\n",
    "albedo = np.array(albedo)\n",
    "\n",
    "c1, c2, c3 = normal\n",
    "\n",
    "n1 = np.zeros(mask.shape)\n",
    "n1[mask!=0] = c1\n",
    "\n",
    "n2 = np.zeros(mask.shape)\n",
    "n2[mask!=0] = c2\n",
    "\n",
    "n3 = np.zeros(mask.shape)\n",
    "n3[mask!=0] = c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a3a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n1, n2, n3: nympy float arrays the 3 components of the normal. They must be 2D arrays\n",
    "# Copying the mask\n",
    "z = utils.simchony_integrate(n1, n2, n3, mask)\n",
    "# z_unbiased = utils.unbiased_integrate(n1, n2, n3, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a6275",
   "metadata": {},
   "outputs": [],
   "source": [
    "z[np.isnan(z)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11bc0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_surface(z, albedo=albedo_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c714262",
   "metadata": {},
   "source": [
    "    Try then to make the estimated normal field smoother using the smooth normal field() function. You may experiment with the iters parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9438ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothing the normal field\n",
    "help(utils.smooth_normal_field)\n",
    "smoothed_normals = utils.smooth_normal_field(n1, n2, n3, mask)\n",
    "\n",
    "n1_s , n2_s, n3_s = smoothed_normals\n",
    "\n",
    "# Solving for depth and displaying the image\n",
    "z = utils.simchony_integrate(n1_s, n2_s, n3_s, mask)\n",
    "utils.display_surface(z, albedo=albedo_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1269cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
